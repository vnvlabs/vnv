@book{tibsh,
author = {Hastie, T.  and Tibshirani, R.  and Friedman, J. H. },
        publisher = {Springer},
        title = {The Elements of Statistical Learning},
        year = {2001}
}

@inproceedings{MaiyaB11,
  author    = {Arun S. Maiya and
               Tanya Y. Berger-Wolf},
  title     = {Benefits of bias: towards better characterization of network
               sampling},
  booktitle = {KDD},
  year      = {2011},
  pages     = {105-113},
  ee        = {http://doi.acm.org/10.1145/2020408.2020431},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@ARTICLE{Demmel2005, 
author={Demmel, J. and Dongarra, J. and Eijkhout, V. and Fuentes, E. and Petitet, A. and Vuduc, R. and Whaley, R.C. and Yelick, K.}, 
journal={Proceedings of the IEEE}, 
title={Self-Adapting Linear Algebra Algorithms and Software}, 
year={2005}, 
month={Feb. }, 
volume={93}, 
number={2}, 
pages={293 -312}, 
abstract={One of the main obstacles to the efficient solution of scientific problems is the problem of tuning software, both to the available architecture and to the user problem at hand. We describe approaches for obtaining tuned high-performance kernels and for automatically choosing suitable algorithms. Specifically, we describe the generation of dense and sparse Basic Linear Algebra Subprograms (BLAS) kernels, and the selection of linear solver algorithms. However, the ideas presented here extend beyond these areas, which can be considered proof of concept.}, 
keywords={BLAS;Basic Linear Algebra Subprograms;high performance kernels;linear solver algorithms;self adapting linear algebra algorithms;self adapting linear algebra software;software libraries;software packages;linear algebra;mathematics computing;operating system kernels;software libraries;software packages;}, 
doi={10.1109/JPROC.2004.840848}, 
ISSN={0018-9219},}

@article{Kriegel:2009:CHD,
 author = {Kriegel, Hans-Peter and Kr\"{o}ger, Peer and Zimek, Arthur},
 title = {Clustering high-dimensional data: A survey on subspace clustering, pattern-based clustering, and correlation clustering},
 journal = {ACM Trans. Knowl. Discov. Data},
 issue_date = {March 2009},
 volume = {3},
 issue = {1},
 month = {March},
 year = {2009},
 issn = {1556-4681},
 pages = {1:1--1:58},
 articleno = {1},
 numpages = {58},
 url = {http://doi.acm.org/10.1145/1497577.1497578},
 doi = {http://doi.acm.org/10.1145/1497577.1497578},
 acmid = {1497578},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Survey, clustering, high-dimensional data},
} 

@article {Brieman2001,
   author = {Breiman, Leo},
   title = {Random Forests},
   journal = {Machine Learning},
   publisher = {Springer Netherlands},
   issn = {0885-6125},
   keyword = {Computer Science},
   pages = {5-32},
   volume = {45},
   issue = {1},
   url = {http://dx.doi.org/10.1023/A:1010933404324},
   note = {10.1023/A:1010933404324},
   abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning : Proceedings of the Thirteenth International conference , ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
   year = {2001}
}

@INCOLLECTION{EijkFuen2010:multistage,
  author = {Victor Eijkhout and Erika Fuentes},
  title = {Machine Learning for Multi-stage Selection of Numerical Methods},
  booktitle = {Machine Learning},
  publisher = {Intech},
  year = {2010}}
  
@techreport{Bhowmick2006,
	author={S. Bhowmick and V. Eijkhout and Y. Freund and E. Fuentes and D. Keyes},
	title={Application of Machine Learning to the Selection of Sparse Linear Solvers}, 
	year = 2006,
	}



@inProceedings{Bhowmick2009,
	title = {Towards Low-Cost and High-Efficiency Classifiers for Linear Solver Selection},
	author = {S. Bhowmick and B. Toth and P. Raghavan}, 
  	booktitle = "Proceedings of the International Conference on Computational Science 2009", 
  	year = 2009,
}
	
@Article{Bhowmick:2004:FGCS,
  title =       "Faster {PDE}-based simulations using robust composite
                 linear solvers",
  author =      "Sanjukta Bhowmick and Padma Raghavan and Lois C.
                 McInnes and Boyana Norris",
  journal =     "Future Generation Computer Systems",
  year =        "2004",
  number =      "3",
  volume =      "20",
  bibdate =     "2004-04-30",
  bibsource =   "DBLP,
                 http://dblp.uni-trier.de/db/journals/fgcs/fgcs20.html#BhowmickRMN04",
  pages =       "373--387",
  URL =         "http://dx.doi.org/10.1016/j.future.2003.07.012",
}

@Manual{Rproject,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Development Core Team}},
    organization = {R Foundation for Statistical Computing},
   address = {Vienna, Austria},
    year = {2008},
    note = {{ISBN} 3-900051-07-0},
    url = {http://www.R-project.org},
}
	
@misc{skikit,
  key={skikit},
  title = {scikit-learn: Machine Learning in Python},
  howpublished = {http://scikit-learn.org/stable/},
  year = {2015}
}

@misc{SUPER,
  key={SUPER},
  title = {SciDAC-3 Institute for Sustained Performance, Energy, and Resilience (SUPER)},
  howpublished = {\url{http://super-scidac.org}},
  year = {2011}
}

@misc{GCO,
  key={Generic},
  title = {Generic Code Optimization},
  howpublished = {\url{http://icl.eecs.utk.edu/gco/}},
  year = {2015}
}

@InProceedings{CHILL:LCPC09,
  author    = {Mary Hall and Jacqueline Chame and Jaewook Shin and Chun Chen and Gabe Rudy and Malik Murtaza Khan},
  booktitle = {Proceedings of the Workshop on Languages and Compilers for Parallel Computing},
  title     = {Loop Transformation Recipes for Code Generation and Auto-Tuning},
  journal   = {The 22nd International Workshop on Languages and Compilers for Parallel Computing},
  year      = {October, 2009}
}

	
@article{ReshefEtAl2011,
	author = {Reshef, David N. and
			Reshef, Yakir A. and
			Finucane, Hilary K. and
			Grossman, Sharon R. and
			McVean, Gilean and
			Turnbaugh, Peter J. and
			Lander, Eric S. and
			Mitzenmacher, Michael and
			Sabeti, Pardis C.},
	title = {Detecting Novel Associations in Large Data Sets},
	volume = {334},
	number = {6062},
	pages = {1518-1524},
	year = {2011},
	doi = {10.1126/science.1205438},
	abstract ={Identifying interesting relationships between pairs of variables in large data sets is increasingly important. Here, we present a measure of dependence for two-variable relationships: the maximal information coefficient (MIC). MIC captures a wide range of associations both functional and not, and for functional relationships provides a score that roughly equals the coefficient of determination (R2) of the data relative to the regression function. MIC belongs to a larger class of maximal information-based nonparametric exploration (MINE) statistics for identifying and classifying relationships. We apply MIC and MINE to data sets in global health, gene expression, major-league baseball, and the human gut microbiota and identify known and novel relationships.},
	URL = {http://www.sciencemag.org/content/334/6062/1518.abstract},
	eprint = {http://www.sciencemag.org/content/334/6062/1518.full.pdf},
	journal = {Science}
}

@article{Kriegel:2009:CHD,
 author = {Kriegel, Hans-Peter and Kr\"{o}ger, Peer and Zimek, Arthur},
 title = {Clustering high-dimensional data: A survey on subspace clustering, pattern-based clustering, and correlation clustering},
 journal = {ACM Trans. Knowl. Discov. Data},
 issue_date = {March 2009},
 volume = {3},
 issue = {1},
 month = {March},
 year = {2009},
 issn = {1556-4681},
 pages = {1:1--1:58},
 articleno = {1},
 numpages = {58},
 url = {http://doi.acm.org/10.1145/1497577.1497578},
 doi = {http://doi.acm.org/10.1145/1497577.1497578},
 acmid = {1497578},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Survey, clustering, high-dimensional data},
} 

@article {Brieman2001,
   author = {Breiman, Leo},
   title = {Random Forests},
   journal = {Machine Learning},
   publisher = {Springer Netherlands},
   issn = {0885-6125},
   keyword = {Computer Science},
   pages = {5-32},
   volume = {45},
   issue = {1},
   url = {http://dx.doi.org/10.1023/A:1010933404324},
   note = {10.1023/A:1010933404324},
   abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning : Proceedings of the Thirteenth International conference , ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
   year = {2001}
}
  
@techreport{Bhowmick2006,
	author={S. Bhowmick and V. Eijkhout and Y. Freund and E. Fuentes and D. Keyes},
	title={Application of Machine Learning to the Selection of Sparse Linear Solvers}, 
	year = 2006,
	}

@incollection{Bhowmick2010:ADT,
	author={S. Bhowmick and V. Eijkhout and Y. Freund and E. Fuentes and D. Keyes},
	title = {Application of Alternating Decision Trees in Selecting Sparse Linear Solvers},
	booktitle = {Software Automatic Tuning: from concepts to state-of-the-art results},
	chapter={10},
	publisher = {Springer-Verlag},
	year= 2010,
}

@inproceedings{Nar:HPDC:2010,
  author="Sri Hari Krishna Narayanan and Boyana Norris and Paul D. Hovland",
  title="Generating Performance Bounds from Source Code",
  booktitle="Proceedings of the First International Workshop on Parallel Software Tools and Tool Infrastructures (PSTI 2010)", 
  institution="Argonne National Laboratory",
  mykeywords="static performance modeling, pbound",
  month = "9",
  year = "2010",
  note = {Also available as Preprint ANL/MCS-P1685-1009},
  URL  = {http://www.mcs.anl.gov/uploads/cels/papers/P1685.pdf},
}

@techreport{Anamod,
  title = {A proposed standard for matrix metadata},
  author = {V. Eijkhout and E. Fuentes},
  institution = {University of Tennessee},
  year = 2003,
  number = {ICL-UT 03-02}
}

@unpublished{bhowmick06,
  title = {Application of Machine Learning to Selecting Solvers for Sparse Linear Systems},
  author = {S. Bhowmick and V. Eijkhout and Y. Freund and E. Fuentes and D. Keyes},
  note = {Presentation at the 2006 SIAM Conf. on Parallel Processing, San Francisco, CA},
  month = {February},
  year = 2006
}

@inProceedings{Bhowmick2009,
	title = {Towards Low-Cost and High-Efficiency Classifiers for Linear Solver Selection},
	author = {S. Bhowmick and B. Toth and P. Raghavan}, 
  	booktitle = "Proceedings of the International Conference on Computational Science 2009", 
  	year = 2009,
}
	

@Manual{Rproject,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Development Core Team}},
    organization = {R Foundation for Statistical Computing},
   address = {Vienna, Austria},
    year = {2008},
    note = {{ISBN} 3-900051-07-0},
    url = {http://www.R-project.org},
}
	
@misc{SUPER,
  key={SUPER},
  title = {SciDAC-3 Institute for Sustained Performance, Energy, and Resilience (SUPER)},
  howpublished = {\url{http://super-scidac.org}},
  year = {2011}
}

@InProceedings{CHILL:LCPC09,
  author    = {Mary Hall and Jacqueline Chame and Jaewook Shin and Chun Chen and Gabe Rudy and Malik Murtaza Khan},
  booktitle = {Proceedings of the Workshop on Languages and Compilers for Parallel Computing},
  title     = {Loop Transformation Recipes for Code Generation and Auto-Tuning},
  journal   = {The 22nd International Workshop on Languages and Compilers for Parallel Computing},
  year      = {October, 2009}
}

@Misc{tau:www,
  title =        {{TAU} -- {Tuning and Analysis Utilities}},
  howpublished = {\url{http://www.cs.uoregon.edu/research/tau/home.php}}}

@Article{Shende:2006:TPP,
  author =       {S. Shende and A. D. Malony},
  title =        {The {TAU} Parallel Performance System},
  journal =      {Intl. J. High Perf. Computing Appl.},
  year =         2006,
  volume =       20,
  number =       2,
  pages =        {287--311},
  month =        {Summer}}

@article{TAU,
          author = {A. Malony and S. Shende and N. Trebon and J. Ray and R. Armstrong and C. Rasmussen and M. Sottile},
           title = {Performance Technology for Parallel and Distributed Component Software},
            year = {2005},
         journal = {Concurrency and Computation: Practice and Experience},
           month = {February},
          number = {2--4},
           pages = {117--141},
          volume = {17},
             url = {http://www.cs.uoregon.edu/research/paracomp/publ/htbin/bibify.cgi?cmd=show&coll=JOUR&id=cca_cpe04&data_present=no
},
      eprint_url = {http://eprints.cca-forum.org/23/}
}

@article{Huck:2008,
 author = {Huck, Kevin A. and Malony, Allen D. and Shende, Sameer and Morris, Alan},
 title = {Knowledge support and automation for performance analysis with {PerfExplorer} 2.0},
 journal = {Sci. Program.},
 issue_date = {April 2008},
 volume = {16},
 number = {2-3},
 month = apr,
 year = {2008},
 issn = {1058-9244},
 pages = {123--134},
 numpages = {12},
 url = {http://dl.acm.org/citation.cfm?id=1402716.1402725},
 acmid = {1402725},
 publisher = {IOS Press},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Parallel performance analysis, data mining, knowledge supported analysis, metadata, scalability, scripting},
} 


	

@inproceedings{OptiML,
  author = {Arvind K. Sujeeth and HyoukJoong Lee and Kevin J. Brown and Tiark Rompf and Hassan Chafi and Michael Wu and Anand R. Atreya and Martin Odersky and Kunle Olukotun},
  title = {{OptiML}: An Implicitly Parallel Domain-Specific Language for Machine Learning},
  booktitle = {Proceedings of the 28th International Conference on Machine Learning, Bellevue, WA},
  year = {2011},
  pages = {609--616},
}

@inproceedings{Natarajan:2009:SLM,
 author = {Natarajan, Ramesh and Sindhwani, Vikas and Tatikonda, Shirish},
 title = {Sparse Least-Squares Methods in the Parallel Machine Learning {(PML)} Framework},
 booktitle = {Proceedings of the 2009 IEEE International Conference on Data Mining Workshops},
 series = {ICDMW '09},
 year = {2009},
 isbn = {978-0-7695-3902-7},
 pages = {314--319},
 numpages = {6},
 url = {http://dx.doi.org/10.1109/ICDMW.2009.106},
 doi = {10.1109/ICDMW.2009.106},
 acmid = {1677160},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 


@inproceedings{Freund:1999:ADT:645528.657623,
 author = {Freund, Yoav and Mason, Llew},
 title = {The Alternating Decision Tree Learning Algorithm},
 booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning},
 series = {ICML '99},
 year = {1999},
 isbn = {1-55860-612-2},
 pages = {124--133},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=645528.657623},
 acmid = {657623},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@article{Bielza:2014:DBN:2620784.2576868,
 author = {Bielza, Concha and Larra\~{n}aga, Pedro},
 title = {Discrete {Bayesian} Network Classifiers: A Survey},
 journal = {ACM Comput. Surv.},
 issue_date = {July 2014},
 volume = {47},
 number = {1},
 month = jul,
 year = {2014},
 issn = {0360-0300},
 pages = {5:1--5:43},
 articleno = {5},
 numpages = {43},
 url = {http://doi.acm.org/10.1145/2576868},
 doi = {10.1145/2576868},
 acmid = {2576868},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Bayesian multinets, Bayesian network, Markov blanket, Supervised classification, feature subset selecti
on, generative and discriminative classifiers, naive Bayes},
} 

@inproceedings{macqueen1967,
address = "Berkeley, Calif.",
author = "MacQueen, J.",
booktitle = "Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics",
pages = "281--297",
publisher = "University of California Press",
title = "Some methods for classification and analysis of multivariate observations",
url = "http://projecteuclid.org/euclid.bsmsp/1200512992",
year = "1967"
}

@article{Breiman:2001:RF:570181.570182,
 author = {Breiman, Leo},
 title = {Random Forests},
 journal = {Mach. Learn.},
 issue_date = {October 1 2001},
 volume = {45},
 number = {1},
 month = oct,
 year = {2001},
 issn = {0885-6125},
 pages = {5--32},
 numpages = {28},
 url = {http://dx.doi.org/10.1023/A:1010933404324},
 doi = {10.1023/A:1010933404324},
 acmid = {570182},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {classification, ensemble, regression},
} 

@INCOLLECTION{scholkopf98,
  AUTHOR = {Bernhard Sch\"{o}lkopf and Chris Burges and Alex Smola},
  TITLE = {Introduction to Support Vector Learning},
  BOOKTITLE = {Advances in Kernel Methods -- Support Vector Learning},
  PUBLISHER = {MIT Press},
  YEAR = {1998},
  PAGES = {1--22},
  EDITOR = {Bernhard Sch\"{o}lkopf and Chris Burges and Alex Smola},
  URL = {},
  ANNOTE = {}
}



@article{knn,
  title={Instance-based learning algorithms},
  author={Aha, David W and Kibler, Dennis and Albert, Marc K},
  journal={Machine learning},
  volume={6},
  number={1},
  pages={37--66},
  year={1991},
  publisher={Springer}
}

@inproceedings{ADT,
  title={The alternating decision tree learning algorithm},
  author={Freund, Yoav and Mason, Llew},
  booktitle={{ICML} '99 Proceedings of the Sixteenth International Conference on Machine Learning},
  volume={99},
  pages={124--133},
publisher = {Morgan Kaufmann},
  year={1999}
}



@inproceedings{RF,
  title={Enhancing random forest implementation in {Weka}},
  author={Pater, N},
  booktitle={Machine learning conference paper for ECE591Q},
  year={2005}
}


@incollection{DecisionStump,
  title={Weka},
  author={Frank, Eibe and Hall, Mark and Holmes, Geoffrey and Kirkby, Richard and Pfahringer, Bernhard and Witten, Ian H and Trigg, Len},
  booktitle={Data Mining and Knowledge Discovery Handbook},
  pages={1305--1314},
  year={2005},
  publisher={Springer}
}

@article{BayesNet,
  title={Bayesian network classifiers in {Weka} for version 3-5-7},
  author={Bouckaert, Remco R},
  journal={Artificial Intelligence Tools},
  volume={11},
  number={3},
  pages={369--387},
  year={2008}
}

@incollection{LADtree,
  title={Multiclass alternating decision trees},
  author={Holmes, Geoffrey and Pfahringer, Bernhard and Kirkby, Richard and Frank, Eibe and Hall, Mark},
  booktitle={Machine learning: ECML 2002},
  pages={161--172},
  year={2002},
  publisher={Springer}
}

@article{Fawcett2006861,
title = "An introduction to {ROC} analysis ",
journal = "Pattern Recognition Letters ",
volume = "27",
number = "8",
pages = "861 - 874",
year = "2006",
issn = "0167-8655",
doi = "http://dx.doi.org/10.1016/j.patrec.2005.10.010",
url = "http://www.sciencedirect.com/science/article/pii/S016786550500303X",
author = "Tom Fawcett",
keywords = "ROC analysis",
keywords = "Classifier evaluation",
keywords = "Evaluation metrics ",
abstract = "Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research. "
}


@inproceedings{VFI,
 author = {Demir\"{o}z, G\"{u}lsen and G\"{u}venir, H. Altay},
 title = {Classification by Voting Feature Intervals},
 booktitle = {Proceedings of the 9th European Conference on Machine Learning},
 series = {ECML '97},
 year = {1997},
 isbn = {3-540-62858-4},
 pages = {85--92},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645325.649678},
 acmid = {649678},
 publisher = {Springer-Verlag},
 address = {London, UK},
} 
  @book{J48,
    address = {San Mateo, CA},
    author = {Ross Quinlan},
    publisher = {Morgan Kaufmann Publishers},
    title = {C4.5: Programs for Machine Learning},
    year = {1993}
 }
  
  @article{Bagging,
    author = {Leo Breiman},
    journal = {Machine Learning},
    number = {2},
    pages = {123-140},
    title = {Bagging predictors},
    volume = {24},
    year = {1996}
 }
 
 @article{SVM,
 author = "Corinna Cortes and Vladimir Vapnik",
 title = "{Support-vector Networks}",
 journal = "Machine Learning",
 volume = "20",
 number = "3",
 pages = "273",
 year = "1995",
}

@article{sisc16,
    author = {Elizabeth Jessup and Pate Motter and Boyana Norris and Kanika Sood},
    title = {Performance-based Numerical Solver Selection in the {L}ighthouse Framework},
    journal = {SIAM Journal on Scientific Computing},
    year = {2016},
    note = {To appear}
   } 
   
@article{ern1994towards,
  title={Towards polyalgorithmic linear system solvers for nonlinear elliptic problems},
  author={Ern, Alexandre and Giovangigli, Vincent and Keyes, David E and Smooke, Mitchell D},
  journal={SIAM Journal on Scientific Computing},
  volume={15},
  number={3},
  pages={681--703},
  year={1994},
  publisher={SIAM}
}

   
   
